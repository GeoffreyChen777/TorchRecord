# TorchRecord

![](https://img.shields.io/badge/torchrecord-v0.0.4-blue.svg)

TorchRecord can merge the small files including images and labels into one or multiple big record file to improve the copying and reading performance.

TorchRecord use LMDB as the storage database. A specific writer and loader can be used to write and read the record.

## Reading Performance Benchmark

Dataset: CUB200 datasets(11788 jpg images)

### Load Image and transform them to tensor (batch_size: 32)

- num_workers = 2:
    ```
    Conventional:    100%|██████████████████| 369/369 [00:42<00:00,  8.72it/s]
    TRLoader:        100%|██████████████████| 369/369 [00:27<00:00, 15.62it/s]
    ```

- num_workers = 4:
    ```
    Conventional:    100%|██████████████████| 369/369 [00:22<00:00, 16.16it/s]
    TRLoader:        100%|██████████████████| 369/369 [00:18<00:00, 19.59it/s]
    ```
## Installation

```bash
pip install torchrecord
```

## Demo

```python
import os
import random
from torchrecord import default_data_process_func
from torchrecord import Writer, TRSampler, TRDataset
import torch.utils.data as data
# =====================================================
# Make data list (txt or csv), one data item per line.
# The template of data_list:
#
# path/to/image/img1.jpg 1
# path/to/image/img2.jpg 2
# ...
# =====================================================

with open('./data_list.txt', 'w') as writer:
    for p, d, fl in os.walk('./testdata'):
        for f in fl:
            if f.endswith('jpg'):
                writer.write("{} {}\n".format(os.path.join(p, f), random.randint(0, 10)))


# =====================================================
# Use torchrecord.Writer to write the torchrecord.
# data_list: the data list
# output_dir: the path of the torchrecord
# db_num: split the origin dataset to n subset
# shuffle: if it is True, the writer will shuffle all the data before writing them to the torchrecord
# data_process_func: the function for processing the data item
# =====================================================

writer = Writer(data_list='./data_list.txt', output_dir='./test_torchrecord', 
                db_num=4, shuffle=True, data_process_func=default_data_process_func)
writer.write()


# =====================================================
# Create a TRSampler and a TRDataset, then send them to the original dataloader of PyTorch
# =====================================================

dataset = TRDataset()
sampler = TRSampler('./test_torchrecord', shuffle=True, batch_size=32)
loader = data.DataLoader(dataset, batch_sampler=sampler, num_workers=2)
for i, batch in enumerate(tqdm(loader)):
    pass

```

## The Detail of the Writer

- data_process_func:

    We list all the data path and label in the data_list file, and use the `data_process_func` to process the data and labels.

    You can define your own `data_process_func` and send them as a parameter to initialize the Writer.

    The `default_data_process_func` are as follows:

    ```python
    def default_data_process_func(data):
        data = data.split(' ')
        tensor_protos = TensorProtos()

        img = Image.open(data[0]).convert("RGB")
        img_tensor = tensor_protos.protos.add()
        img_tensor.dims.extend(img.size)
        img_tensor.data_type = 3
        img_tensor.byte_data = img.tobytes()

        label_tensor = tensor_protos.protos.add()
        label_data = str.encode(data[1])
        label_tensor.data_type = 3
        label_tensor.byte_data = label_data
        return tensor_protos
    ```

    The `data` parameter is one line of your data_list file. 

    We use the TensorProtos which is a *Buffer Protocols* (designed by Google) object as the data structure. You can save your data in TensorProtos
    and return it. Then, the writer will save the TensorProtos into LMDB.
    

## The Detail of the TRDataset and the TRSampler

The TRSampler is used to sample the raw byte string from the torchrecord(lmdb). It will generate the random raw byte batch if `shuffle=True`.
```python
class TRSampler(data.Sampler):
    def __init__(self, record_path, shuffle=False, batch_size=1):
```

- record_path

    This is your record path.
    
Then, the dataloader of PyTorch will distribute the raw byte item in the raw batch generated by the TRSampler to TRDataset. TRDataset will parse the raw byte string to the TensorProtos and apply the transform to it. Finally, TRDataset will return the iamge tensor and the label to the dataloader. The dataloader will use the `collate_fn` to construct the final batch.

```python
class TRDataset(data.Dataset):
    def __init__(self, transform=default_transform, proto=TensorProtos):
```

- transform

    This is the transform function for decode the byte string to the tensor_protos. You can also do any torchvision transforms here.

    The default transform is like this:

    ```python
    from PIL import Image
    import torchvision.transforms as tvt


    trans = tvt.Compose([
        tvt.Resize((224, 224)),
        tvt.ToTensor()
    ])

    def default_transform(tensor_protos):
        img_proto = tensor_protos.protos[0]
        img = Image.frombytes(mode='RGB', size=tuple(img_proto.dims), data=img_proto.byte_data)
        img = trans(img)
        label = int(tensor_protos.protos[1].byte_data)
        return img, label
    ```
